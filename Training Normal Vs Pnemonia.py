# -*- coding: utf-8 -*-
"""Pnemonia9422Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o1IMAkTbdEUQqL4M8Vzi2WbnQj79LMoG

#**Import Data from Kaggle**
"""

from google.colab import files
files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle 
!cp kaggle.json ~/.kaggle/ 
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

!unzip /content/chest-xray-pneumonia.zip

"""# **Preparation Of Validation Dataset**"""

!ls -1 /content/chest_xray/chest_xray/train/NORMAL | wc -l
!ls -1 /content/chest_xray/chest_xray/train/PNEUMONIA | wc -l

valnorm=!ls /content/chest_xray/chest_xray/train/NORMAL/ | shuf -n 262
for i in range(len(valnorm)):
  valnorm[i]='/content/chest_xray/chest_xray/train/NORMAL/'+valnorm[i]

for i in valnorm:
  a=i
  !mv "$a" /content/chest_xray/chest_xray/val/NORMAL

valpnem=!ls /content/chest_xray/chest_xray/train/PNEUMONIA/ | shuf -n 768
for i in range(len(valpnem)):
  valpnem[i]='/content/chest_xray/chest_xray/train/PNEUMONIA/'+valpnem[i]

for i in valpnem:
  b=i
  !mv "$b" /content/chest_xray/chest_xray/val/PNEUMONIA

!ls -1 /content/chest_xray/chest_xray/train/NORMAL | wc -l
!ls -1 /content/chest_xray/chest_xray/val/NORMAL | wc -l
!ls -1 /content/chest_xray/chest_xray/train/PNEUMONIA | wc -l
!ls -1 /content/chest_xray/chest_xray/val/PNEUMONIA | wc -l

"""# **Import Necessary Libraries**"""

import torchvision.datasets as datasets
from torchvision import transforms
import os
from torch.utils.data import WeightedRandomSampler,DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch
import numpy as np

"""# **Data PreProcessing**"""

data_transform=transforms.Compose([transforms.Resize(256),transforms.ColorJitter(),transforms.RandomCrop(224),transforms.RandomHorizontalFlip(),transforms.Resize(256),transforms.ToTensor()])

dataset_train=datasets.ImageFolder(root='/content/chest_xray/chest_xray/train',transform=data_transform)

dataset_val=datasets.ImageFolder(root='/content/chest_xray/chest_xray/val',transform=data_transform)

"""# **OverSampling : Weighted Random Sampling**

**Removal of .DS_Store Files**
"""

cd /content/chest_xray/chest_xray/train

!find . -name '.DS_Store' -type f -delete

cd /content/chest_xray/chest_xray/val

!find . -name '.DS_Store' -type f -delete

"""**Applying Class Weights , Finding Sample weights**"""

class_weights_train=[]
for root,subdir,files in os.walk('/content/chest_xray/chest_xray/train'):
  if len(files)>0:
    class_weights_train.append(1/len(files))
    print(files)
class_weights_val=[]
for root,subdir,files in os.walk('/content/chest_xray/chest_xray/val'):
  if len(files)>0:
    class_weights_val.append(1/len(files))
    print(files)

print(class_weights_train,class_weights_val)
sample_weights_train=[0]*len(dataset_train)
sample_weights_val=[0]*len(dataset_val)

for idx,(data,label) in enumerate(dataset_train):
  class_weight_train=class_weights_train[label]
  sample_weights_train[idx]=class_weight_train

for idx,(data,label) in enumerate(dataset_val):
  class_weight_val=class_weights_val[label]
  sample_weights_val[idx]=class_weight_val

"""# **Loading Data into DataLoader**"""

sampler_train=WeightedRandomSampler(sample_weights_train,num_samples=len(sample_weights_train),replacement=True)
loader_train=DataLoader(dataset_train,batch_size=16,sampler=sampler_train)
sampler_val=WeightedRandomSampler(sample_weights_val,num_samples=len(sample_weights_val),replacement=True)
loader_val=DataLoader(dataset_val,batch_size=16,sampler=sampler_val)

"""#**The CNN Model**"""

class Net(nn.Module):
  def __init__(self):
    super().__init__()
    #256X256
    self.conv1=nn.Conv2d(3,32,kernel_size=3,padding=1)
    self.conv1_batchnorm=nn.BatchNorm2d(num_features=32)
    self.act1=nn.ReLU()
    self.pool1=nn.MaxPool2d(2)
    self.conv1_dropout=nn.Dropout2d(p=0.2)
 #128X128
    self.conv2=nn.Conv2d(32,64,kernel_size=3,padding=1)
    self.conv2_batchnorm=nn.BatchNorm2d(num_features=64)
    self.act2=nn.ReLU()
    self.pool2=nn.MaxPool2d(2)
    self.conv2_dropout=nn.Dropout2d(p=0.2)
 #64X64
    self.conv3=nn.Conv2d(64,64,kernel_size=3,padding=1)
    self.conv3_batchnorm=nn.BatchNorm2d(num_features=64)
    self.act3=nn.ReLU()
    self.pool3=nn.MaxPool2d(2)
    self.conv3_dropout=nn.Dropout2d(p=0.2)
 #32X32
    self.conv4=nn.Conv2d(64,32,kernel_size=3,padding=1)
    self.conv4_batchnorm=nn.BatchNorm2d(num_features=32)
    self.act4=nn.ReLU()
    self.pool4=nn.MaxPool2d(2)
    self.conv4_dropout=nn.Dropout2d(p=0.2)
 #16X16
    self.fc1=nn.Linear(32*16*16,64)
    self.act5=nn.ReLU()
    self.fc2=nn.Linear(64,2)
  def forward(self,x):
    out=self.pool1(self.act1(self.conv1_batchnorm(self.conv1(x))))
    out=self.conv1_dropout(out)
    
    out=self.pool2(self.act2(self.conv2_batchnorm(self.conv2(out))))
    out=self.conv2_dropout(out)
 
    out=self.pool3(self.act3(self.conv3_batchnorm(self.conv3(out))))
    out=self.conv3_dropout(out)
 
    out=self.pool4(self.act4(self.conv4_batchnorm(self.conv4(out))))
    out=self.conv4_dropout(out)
    out=out.view(-1,32*16*16)
    
    out=self.act5(self.fc1(out))
    out=self.fc2(out)
    return out

model=Net()
for t in model.parameters():
  print(t.shape)

for images,labels in loader_train:
  print(images.shape)
  out=model(images)
  print(out.shape)
  print(out[0])
  break
F.softmax(out[0])

"""# **Loading Data Into Cuda**"""

torch.cuda.is_available()
def get_default_device():
  if torch.cuda.is_available():
    return torch.device('cuda')
  else:
    return torch.device('cpu')

device=get_default_device()
print(device)
def to_device(data,device):
  if isinstance(data,(list,tuple)):
    return [to_device(x,device)for x in data]
  return data.to(device,non_blocking=True)

for images,labels in loader_train:
  print(images.shape)
  images=to_device(images,device)
  print(images.device)
  break

class DeviceDataLoader():
  def __init__(self,dl,device):
    self.dl=dl
    self.device=device

  def __iter__(self):
    for b in self.dl:
      yield to_device(b,self.device)
  def __len__(self):
    return len(self.dl)

train_dl=DeviceDataLoader(loader_train,device)
valid_dl=DeviceDataLoader(loader_val,device)
for xb,yb in valid_dl:
  print(xb.shape)
  print(yb.shape)
  break

"""# **Training Functions**"""

def evaluate(model,loss_fn,valid_dl,metric=None):
  with torch.no_grad():
    results=[loss_batch(model,loss_fn,xb,yb,metric=metric)for xb,yb in valid_dl]
    #print(results)
    losses,nums,metrics=zip(*results)
    total=np.sum(nums)
    avg_loss=np.sum(np.multiply(losses,nums))/total
    avg_metric=None
    if metric is not None:
      avg_metric=np.sum(np.multiply(metrics,nums))/total
  return avg_loss,total,avg_metric

def loss_batch(model,loss_func,xb,yb,opt=None,metric=None):
  preds=model(xb)
  #print(preds.shape,yb.shape)
  loss=loss_func(preds,yb)
 
  if opt is not None:
    loss.backward()
    opt.step()
    opt.zero_grad()
 
  metric_result=None
  if metric is not None:
    metric_result=metric(preds,yb)
  return loss.item(),len(xb),metric_result

def fit(epochs,lr,model,loss_fn,train_dl,valid_dl,metric=None,opt_fn=None):
  losses,metrics=[],[]
  if opt_fn is None:opt_fn=torch.optim.Adam
  opt=torch.optim.Adam(model.parameters(),lr=lr)
 
  for epoch in range(epochs):
    for xb,yb in train_dl:
      loss,_,_=loss_batch(model,loss_fn,xb,yb,opt)
 
    result=evaluate(model,loss_fn,valid_dl,metric)
    val_loss,total,val_metric=result
 
    losses.append(val_loss)
    metrics.append(val_metric)
 
    if metric is None:
      print('Epoch [{}/{}],Loss: {:.4f'.format(epoch+1,epochs,val_loss))
    else:
      print('Epoch [{}/{}],Loss: {:.4f}, Accuracy {:.4f}'.format(epoch+1,epochs,val_loss,val_metric))
  
  return losses,metrics

def accuracy(outputs,labels):
  s=0
  _,preds=torch.max(outputs,dim=1)
  s=s+torch.sum(preds==1).item()
  print(s)
  #print(torch.sum(preds==labels).item())
  return torch.sum(preds==labels).item()/len(preds)

to_device(model,device)

"""# **Training**"""

val_loss,total,val_acc=evaluate(model,F.cross_entropy,valid_dl,metric=accuracy)
print('Loss: {:.4f}, Accuracy: {:.4f}'.format(val_loss,val_acc))

losses1,metrics1=fit(10,0.1,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

cd /content/chest_xray

ls

torch.save(model.state_dict(),'model9080.pt')

!ls

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model9422.pt')

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

torch.save(model.state_dict(),'model9364contcpunt10.pt')

from google.colab import files
files.upload()

device = torch.device("cuda")
model.load_state_dict(torch.load('model9422.pt'))
model.to(device)

model.eval()

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

losses2,metrics2=fit(10,0.01,model,F.cross_entropy,train_dl,valid_dl,accuracy)

