# -*- coding: utf-8 -*-
"""PnemoniaTesting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EmkhHFmVGdiIQ666BL7YIQpa3IPNnEAB

# **Import Data From Kaggle**
"""

from google.colab import files
files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle 
!cp kaggle.json ~/.kaggle/ 
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

!unzip /content/chest-xray-pneumonia.zip

"""# **Importing Libraries**"""

import torchvision.datasets as datasets
from torchvision import transforms
import os
from torch.utils.data import WeightedRandomSampler,DataLoader
import torch.nn as nn
import torch.nn.functional as F
import torch
import numpy as np

"""# **DataPreProcessing And Loading Data into DataLoader**"""

data_transform=transforms.Compose([transforms.Resize(256),transforms.ColorJitter(),transforms.RandomCrop(224),transforms.RandomHorizontalFlip(),transforms.Resize(256),transforms.ToTensor()])

dataset_test=datasets.ImageFolder(root='/content/chest_xray/chest_xray/test',transform=data_transform)

testloader = DataLoader(dataset_test, batch_size = 8, shuffle=False, num_workers=2)

"""# **The CNN Model**"""

class Net(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1=nn.Conv2d(3,32,kernel_size=3,padding=1)
    self.conv1_batchnorm=nn.BatchNorm2d(num_features=32)
    self.act1=nn.ReLU()
    self.pool1=nn.MaxPool2d(2)
    self.conv1_dropout=nn.Dropout2d(p=0.2)

    self.conv2=nn.Conv2d(32,64,kernel_size=3,padding=1)
    self.conv2_batchnorm=nn.BatchNorm2d(num_features=64)
    self.act2=nn.ReLU()
    self.pool2=nn.MaxPool2d(2)
    self.conv2_dropout=nn.Dropout2d(p=0.2)

    self.conv3=nn.Conv2d(64,64,kernel_size=3,padding=1)
    self.conv3_batchnorm=nn.BatchNorm2d(num_features=64)
    self.act3=nn.ReLU()
    self.pool3=nn.MaxPool2d(2)
    self.conv3_dropout=nn.Dropout2d(p=0.2)

    self.conv4=nn.Conv2d(64,32,kernel_size=3,padding=1)
    self.conv4_batchnorm=nn.BatchNorm2d(num_features=32)
    self.act4=nn.ReLU()
    self.pool4=nn.MaxPool2d(2)
    self.conv4_dropout=nn.Dropout2d(p=0.2)

    self.fc1=nn.Linear(32*16*16,64)
    self.act5=nn.ReLU()
    self.fc2=nn.Linear(64,2)
  def forward(self,x):
    out=self.pool1(self.act1(self.conv1_batchnorm(self.conv1(x))))
    out=self.conv1_dropout(out)
    
    out=self.pool2(self.act2(self.conv2_batchnorm(self.conv2(out))))
    out=self.conv2_dropout(out)

    out=self.pool3(self.act3(self.conv3_batchnorm(self.conv3(out))))
    out=self.conv3_dropout(out)

    out=self.pool4(self.act4(self.conv4_batchnorm(self.conv4(out))))
    out=self.conv4_dropout(out)
    out=out.view(-1,32*16*16)
    
    out=self.act5(self.fc1(out))
    out=self.fc2(out)
    return out

"""# **Uploading Weights**"""

from google.colab import files
PATH=files.upload()

"""# **Loading Model Into Cuda**"""

model=Net()

device = 'cuda'

device = torch.device("cuda")
model.load_state_dict(torch.load('model9422.pt'))
model.to(device)

model.eval()

"""# **Loading TestData Into Cuda**"""

def get_default_device():
  if torch.cuda.is_available():
    return torch.device('cuda')
  else:
    return torch.device('cpu')

device=get_default_device()
device

def to_device(data,device):
  if isinstance(data,(list,tuple)):
    return [to_device(x,device)for x in data]
  return data.to(device,non_blocking=True)

class DeviceDataLoader():
  def __init__(self,dl,device):
    self.dl=dl
    self.device=device

  def __iter__(self):
    for b in self.dl:
      yield to_device(b,self.device)
  def __len__(self):
    return len(self.dl)

testloader=DeviceDataLoader(testloader,device)

"""# **Calculating Loss and Accuracy**"""

def loss_batch(model,loss_func,xb,yb,metric=None):
  preds=model(xb)
  #print(preds)
  loss=loss_func(preds,yb)

  metric_result=None
  if metric is not None:
    metric_result=metric(preds,yb)
  return loss.item(),len(xb),metric_result

def accuracy(outputs,labels):
  _,preds=torch.max(outputs,dim=1)
  #print('prediction:{},labels:{}'.format(preds,labels))
  return torch.sum(preds==labels).item()/len(preds)

def evaluate(model,loss_fn,testloader,metric=None):
  with torch.no_grad():
    results=[loss_batch(model,loss_fn,xb,yb,metric=metric)for xb,yb in testloader]
    #print(results)
    losses,nums,metrics=zip(*results)
    total=np.sum(nums)
    avg_loss=np.sum(np.multiply(losses,nums))/total
    avg_metric=None
    if metric is not None:
      avg_metric=np.sum(np.multiply(metrics,nums))/total
  return avg_loss,total,avg_metric

test_loss,total,test_acc=evaluate(model,F.cross_entropy,testloader,metric=accuracy)
print('Loss: {:.4f}, Accuracy: {:.4f}'.format(test_loss,test_acc))

